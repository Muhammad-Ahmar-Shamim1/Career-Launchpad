{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193b16d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocess import load_and_preprocess\n",
    "\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 2\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.encodings = tokenizer(\n",
    "            texts, truncation=True, padding=True, max_length=128\n",
    "        )\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Load data\n",
    "df = load_and_preprocess(\"data/reviews.csv\")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df['clean_text'], df['label'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = SentimentDataset(X_train.tolist(), y_train.tolist())\n",
    "val_dataset = SentimentDataset(X_val.tolist(), y_val.tolist())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Training Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Save model\n",
    "model.save_pretrained(\"models/bert_sentiment_model\")\n",
    "tokenizer.save_pretrained(\"models/bert_sentiment_model\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
